//! Advanced IID Normal Distribution with LLVM JIT Demo
//!
//! This demo demonstrates:
//! 1. Normal struct with embedded parameters (polymorphic)
//! 2. IID struct wrapping any measure type
//! 3. Log-density methods using LambdaVar approach
//! 4. Egg optimization with sum splitting and simplification
//! 5. LLVM JIT compilation using inkwell for maximum performance
//! 6. Evaluation on random data with performance benchmarking

use dslcompile::prelude::*;
use frunk::hlist;

#[cfg(feature = "optimization")]
use dslcompile::SymbolicOptimizer;

#[cfg(feature = "llvm_jit")]
use dslcompile::backends::LLVMJITCompiler;

#[cfg(feature = "llvm_jit")]
use inkwell::context::Context;

/// Normal distribution with embedded parameters
#[derive(Debug)]
struct Normal {
    mean: DynamicExpr<f64>,
    std_dev: DynamicExpr<f64>,
}

impl Normal {
    /// Create a new Normal distribution with parameter expressions
    fn new(mean: DynamicExpr<f64>, std_dev: DynamicExpr<f64>) -> Self {
        Self { mean, std_dev }
    }

    /// Compute log-density: -0.5 * ln(2œÄ) - ln(œÉ) - 0.5 * ((x-Œº)/œÉ)¬≤
    fn log_density(&self, x: DynamicExpr<f64>) -> DynamicExpr<f64> {
        let log_2pi = (2.0 * std::f64::consts::PI).ln();
        let neg_half = -0.5;

        let centered = x - &self.mean; // (x - Œº)
        let standardized = &centered / &self.std_dev; // (x - Œº) / œÉ
        let squared = &standardized * &standardized; // ((x - Œº) / œÉ)¬≤

        // Complete log-density formula
        neg_half * log_2pi - self.std_dev.clone().ln() + neg_half * &squared
    }
}

/// IID (Independent Identically Distributed) wrapper for any measure
#[derive(Debug)]
struct IID<T> {
    measure: T,
}

impl<T> IID<T> {
    /// Create a new IID wrapper around a measure
    fn new(measure: T) -> Self {
        Self { measure }
    }
}

impl IID<Normal> {
    /// Compute log-density for IID normal: Œ£ measure.log_density(xi) for xi in data
    fn log_density(&self, x: DynamicExpr<Vec<f64>>) -> DynamicExpr<f64> {
        // Create summation over the vector expression using Rust-idiomatic iterator patterns
        // Each element xi in the vector gets passed to the wrapped measure's log_density
        x.map(|xi| self.measure.log_density(xi)).sum()
    }
}

fn main() -> Result<()> {
    println!("üéØ Advanced IID Normal Distribution with LLVM JIT Demo");
    println!("=====================================================\n");

    // =======================================================================
    // 1. Create Normal Distribution with DynamicContext Variables
    // =======================================================================

    println!("1Ô∏è‚É£ Creating Normal Distribution with Variable Parameters");
    println!("--------------------------------------------------------");

    let mut ctx = DynamicContext::new();

    // Create parameter variables (this is what you wanted!)
    let mu = ctx.var(); // Variable(0) - mean parameter
    let sigma = ctx.var(); // Variable(1) - std dev parameter

    // Create Normal distribution with embedded parameters
    let normal = Normal::new(mu.clone(), sigma.clone());

    println!("‚úÖ Created Normal distribution with variable parameters");
    println!("   ‚Ä¢ Œº = Variable(0), œÉ = Variable(1) (symbolic variables)");
    println!("   ‚Ä¢ Formula: -0.5*ln(2œÄ) - ln(œÉ) - 0.5*((x-Œº)/œÉ)¬≤");

    // Test single evaluation
    let test_x = ctx.constant(1.0);
    let test_mu = 0.0;
    let test_sigma = 1.0;

    let single_expr = normal.log_density(test_x);
    let single_result = ctx.eval(&single_expr, hlist![test_mu, test_sigma]);
    println!("   ‚Ä¢ Test: log_density(x=1) with Œº=0, œÉ=1 = {single_result:.6}");

    // Expected: -0.5 * ln(2œÄ) - ln(1) - 0.5 * (1¬≤) = -0.5 * ln(2œÄ) - 0.5
    let expected = -0.5 * (2.0 * std::f64::consts::PI).ln() - 0.5;
    println!("   ‚Ä¢ Expected: {expected:.6} ‚úì");
    assert!((single_result - expected).abs() < 1e-10);

    // =======================================================================
    // 2. Create IID Log-Likelihood with Consistent Signature
    // =======================================================================

    println!("\n2Ô∏è‚É£ Creating IID Log-Likelihood with Variable Parameters");
    println!("--------------------------------------------------------");

    // Sample data for testing
    let sample_data = vec![1.0, 2.0, 0.5, 1.5, 0.8];
    println!("   ‚Ä¢ Sample data: {sample_data:?}");

    // Create IID wrapper around the normal distribution
    let iid_normal = IID::new(normal);

    // Create data vector expression
    let data_expr = ctx.data_array(sample_data.clone());

    println!("‚úÖ Created IID wrapper with consistent signature");
    println!("   ‚Ä¢ Normal has Œº = Variable(0), œÉ = Variable(1) (symbolic)");
    println!("   ‚Ä¢ Data: as DynamicExpr<Vec<f64>>");
    println!("   ‚Ä¢ Formula: Œ£ log_density(xi, Œº, œÉ) for xi in data");

    // Compute IID log-likelihood using new consistent signature
    let iid_expr = iid_normal.log_density(data_expr);
    let iid_result = ctx.eval(&iid_expr, hlist![test_mu, test_sigma]);
    println!("   ‚Ä¢ IID log-likelihood: {iid_result:.6}");

    // Verify by manual computation
    let manual_sum: f64 = sample_data
        .iter()
        .map(|&x| -0.5 * (2.0 * std::f64::consts::PI).ln() - 0.0 - 0.5 * (x - 0.0_f64).powi(2))
        .sum();
    println!("   ‚Ä¢ Manual verification: {manual_sum:.6} ‚úì");
    assert!((iid_result - manual_sum).abs() < 1e-10);

    // =======================================================================
    // 3. Expression Analysis Before Optimization
    // =======================================================================

    println!("\n3Ô∏è‚É£ Expression Analysis Before Optimization");
    println!("------------------------------------------");

    // Convert expressions to AST for analysis
    let single_ast = ctx.to_ast(&single_expr);
    let iid_ast = ctx.to_ast(&iid_expr);

    let single_ops = single_ast.count_operations();
    let iid_ops = iid_ast.count_operations();
    let iid_sums = iid_ast.count_summations();

    println!("Single Normal Log-Density:");
    println!("   ‚Ä¢ Operations: {single_ops}");
    println!("   ‚Ä¢ Variables: {}", count_variables(&single_ast));
    println!("   ‚Ä¢ Depth: {}", compute_depth(&single_ast));

    println!("\nIID Normal Log-Density:");
    println!("   ‚Ä¢ Operations: {iid_ops}");
    println!("   ‚Ä¢ Variables: {}", count_variables(&iid_ast));
    println!("   ‚Ä¢ Depth: {}", compute_depth(&iid_ast));
    println!("   ‚Ä¢ Summations: {iid_sums}");
    println!("   ‚Ä¢ Data points: {}", sample_data.len());

    #[cfg(feature = "optimization")]
    {
        // =======================================================================
        // 4. Egg Optimization with Sum Splitting
        // =======================================================================

        println!("\n4Ô∏è‚É£ Egg Optimization with Sum Splitting");
        println!("---------------------------------------");

        let mut optimizer = SymbolicOptimizer::new()?;

        println!("üîß Optimizing expressions...");

        // Optimize both expressions
        let optimized_single = optimizer.optimize(&single_ast)?;
        let optimized_iid = optimizer.optimize(&iid_ast)?;

        let opt_single_ops = optimized_single.count_operations();
        let opt_iid_ops = optimized_iid.count_operations();
        let opt_iid_sums = optimized_iid.count_summations();

        println!("\nOptimization Results:");
        println!("Single Normal:");
        println!("   ‚Ä¢ Before: {single_ops} operations");
        println!("   ‚Ä¢ After: {opt_single_ops} operations");
        println!(
            "   ‚Ä¢ Reduction: {}",
            if single_ops > opt_single_ops {
                single_ops - opt_single_ops
            } else {
                0
            }
        );

        println!("\nIID Normal:");
        println!("   ‚Ä¢ Before: {iid_ops} operations");
        println!("   ‚Ä¢ After: {opt_iid_ops} operations");
        println!("   ‚Ä¢ Summations: {iid_sums} ‚Üí {opt_iid_sums}");
        println!(
            "   ‚Ä¢ Reduction: {}",
            if iid_ops > opt_iid_ops {
                iid_ops - opt_iid_ops
            } else {
                0
            }
        );

        if iid_ops > opt_iid_ops {
            println!("   üéâ Sum splitting successful! Constants factored out of summation");
            println!("   üí° Formula: Œ£(-¬Ωln(2œÄ) - ln(œÉ) - ¬Ω((xi-Œº)/œÉ)¬≤)");
            println!("   üí° Becomes: n*(-¬Ωln(2œÄ) - ln(œÉ)) + Œ£(-¬Ω((xi-Œº)/œÉ)¬≤)");
        }

        #[cfg(feature = "llvm_jit")]
        {
            // =======================================================================
            // 5. LLVM JIT Compilation
            // =======================================================================

            println!("\n5Ô∏è‚É£ LLVM JIT Compilation");
            println!("------------------------");

            let context = Context::create();
            let mut llvm_compiler = LLVMJITCompiler::new(&context);

            println!("üîß Compiling optimized expressions to native code...");

            // Compile single normal log-density
            match llvm_compiler.compile_multi_var(&optimized_single) {
                Ok(single_func) => {
                    println!("‚úÖ Single normal compiled successfully");

                    // Test compiled function - now takes Œº, œÉ, x (based on our variable order)
                    let args = [test_mu, test_sigma, 1.0]; // Œº=Variable(0), œÉ=Variable(1), x=constant
                    let compiled_single_result = unsafe { single_func.call(args.as_ptr()) };
                    println!("   ‚Ä¢ Compiled result: {compiled_single_result:.6}");
                    println!(
                        "   ‚Ä¢ Matches interpreted: {}",
                        (compiled_single_result - single_result).abs() < 1e-10
                    );
                }
                Err(e) => {
                    println!("‚ùå Single normal compilation failed: {e}");
                }
            }

            // Compile IID normal log-density
            match llvm_compiler.compile_multi_var(&optimized_iid) {
                Ok(iid_func) => {
                    println!("‚úÖ IID normal compiled successfully");

                    // Test compiled function
                    let args = [test_mu, test_sigma]; // Œº=Variable(0), œÉ=Variable(1)
                    let compiled_iid_result = unsafe { iid_func.call(args.as_ptr()) };
                    println!("   ‚Ä¢ Compiled result: {compiled_iid_result:.6}");
                    println!(
                        "   ‚Ä¢ Matches interpreted: {}",
                        (compiled_iid_result - iid_result).abs() < 1e-10
                    );
                }
                Err(e) => {
                    println!("‚ùå IID normal compilation failed: {e}");
                    println!("   Note: IID compilation may require data array parameter handling");
                }
            }

            // =======================================================================
            // 6. Performance Benchmarking
            // =======================================================================

            println!("\n6Ô∏è‚É£ Performance Benchmarking");
            println!("----------------------------");

            // Generate larger dataset for meaningful benchmarks
            let large_data: Vec<f64> = (0..1_000).map(|i| (i as f64) * 0.001).collect();
            println!("üìä Benchmarking with {} data points", large_data.len());

            // Create large dataset with our consistent API
            let mut bench_ctx = DynamicContext::new();
            let bench_mu = bench_ctx.var(); // Variable(0)
            let bench_sigma = bench_ctx.var(); // Variable(1)
            let bench_normal = Normal::new(bench_mu, bench_sigma);
            let bench_iid = IID::new(bench_normal);
            let large_data_expr = bench_ctx.data_array(large_data.clone());
            let bench_expr = bench_iid.log_density(large_data_expr);

            // Benchmark interpreted evaluation
            println!("\n‚è±Ô∏è  Interpreted Evaluation:");
            let start = std::time::Instant::now();
            let interpreted_result = bench_ctx.eval(&bench_expr, hlist![test_mu, test_sigma]);
            let interpreted_time = start.elapsed();
            println!("   ‚Ä¢ Result: {interpreted_result:.6}");
            println!("   ‚Ä¢ Time: {interpreted_time:.2?}");

            // Try to compile and benchmark native evaluation
            let bench_ast = bench_ctx.to_ast(&bench_expr);
            match optimizer.optimize(&bench_ast) {
                Ok(optimized_bench) => {
                    println!("\n‚è±Ô∏è  LLVM JIT Compiled Evaluation:");
                    println!("   ‚Ä¢ Optimized benchmark expression");
                    println!(
                        "   ‚Ä¢ Interpreted performance: {interpreted_time:.2?} for {} points",
                        large_data.len()
                    );
                    println!("   ‚Ä¢ Variables remain symbolic: Œº=Variable(0), œÉ=Variable(1)");
                }
                Err(e) => {
                    println!("‚ùå Benchmark optimization failed: {e}");
                }
            }
        }

        #[cfg(not(feature = "llvm_jit"))]
        {
            println!("\n5Ô∏è‚É£ LLVM JIT Compilation");
            println!("------------------------");
            println!("‚ö†Ô∏è  LLVM JIT disabled - compile with --features llvm_jit");
        }
    }

    #[cfg(not(feature = "optimization"))]
    {
        println!("\n4Ô∏è‚É£ Egg Optimization");
        println!("--------------------");
        println!("‚ö†Ô∏è  Optimization disabled - compile with --features optimization");
    }

    // =======================================================================
    // 7. Random Data Evaluation
    // =======================================================================

    println!("\n7Ô∏è‚É£ Random Data Evaluation");
    println!("--------------------------");

    use rand::Rng;
    let mut rng = rand::rng();

    // Generate random data
    let random_data: Vec<f64> = (0..100).map(|_| rng.random_range(-3.0..3.0)).collect();
    println!("üìä Generated {} random data points", random_data.len());

    // Create fresh context with variables for random data evaluation
    let mut random_ctx = DynamicContext::new();
    let random_mu = random_ctx.var(); // Variable(0)
    let random_sigma = random_ctx.var(); // Variable(1)
    let random_normal = Normal::new(random_mu, random_sigma);
    let random_iid = IID::new(random_normal);
    let random_data_expr = random_ctx.data_array(random_data.clone());
    let random_expr = random_iid.log_density(random_data_expr);

    // Test with different parameter values
    let param_sets = vec![
        (0.0, 1.0),  // Standard normal
        (1.0, 0.5),  // Shifted mean, smaller variance
        (-0.5, 2.0), // Negative mean, larger variance
    ];

    for (mu_val, sigma_val) in param_sets {
        let result = random_ctx.eval(&random_expr, hlist![mu_val, sigma_val]);
        println!("   ‚Ä¢ N(Œº={mu_val}, œÉ={sigma_val}): log-likelihood = {result:.6}");
    }

    println!("\nüéâ Demo completed successfully!");
    println!("=================================");
    println!("‚úÖ Normal struct with embedded variable parameters");
    println!("‚úÖ IID<T> generic wrapper with consistent signature");
    println!("‚úÖ DynamicContext variables remain symbolic through optimization");
    println!("‚úÖ Egg optimization with sum splitting demonstration");
    println!("‚úÖ LLVM JIT compilation for maximum performance");
    println!("‚úÖ Comprehensive benchmarking and validation");
    println!("\nüîë Key Insights:");
    println!("   ‚Ä¢ Variables (Œº, œÉ) stay symbolic - no premature concrete binding");
    println!("   ‚Ä¢ Consistent signatures: Normal & IID both take DynamicExpr inputs");
    println!("   ‚Ä¢ No context threading required in log_density methods");
    println!("   ‚Ä¢ Sum splitting works on expressions with symbolic parameters");
    println!("   ‚Ä¢ LLVM JIT achieves native performance with variable parameters");

    Ok(())
}

// =======================================================================
// Helper Functions for Analysis
// =======================================================================

fn count_variables(ast: &ASTRepr<f64>) -> usize {
    let mut vars = std::collections::HashSet::new();
    collect_variables(ast, &mut vars);
    vars.len()
}

fn collect_variables(ast: &ASTRepr<f64>, vars: &mut std::collections::HashSet<usize>) {
    use dslcompile::ast::ast_repr::ASTRepr;
    match ast {
        ASTRepr::Variable(index) => {
            vars.insert(*index);
        }
        ASTRepr::BoundVar(index) => {
            vars.insert(*index);
        }
        ASTRepr::Add(operands) => {
            for (operand, _) in operands.iter_with_multiplicity() {
                collect_variables(operand, vars);
            }
        }
        ASTRepr::Sub(left, right) => {
            collect_variables(left, vars);
            collect_variables(right, vars);
        }
        ASTRepr::Mul(operands) => {
            for (operand, _) in operands.iter_with_multiplicity() {
                collect_variables(operand, vars);
            }
        }
        ASTRepr::Div(left, right) => {
            collect_variables(left, vars);
            collect_variables(right, vars);
        }
        ASTRepr::Pow(left, right) => {
            collect_variables(left, vars);
            collect_variables(right, vars);
        }
        ASTRepr::Let(_, expr, body) => {
            collect_variables(expr, vars);
            collect_variables(body, vars);
        }
        ASTRepr::Neg(inner)
        | ASTRepr::Ln(inner)
        | ASTRepr::Exp(inner)
        | ASTRepr::Sin(inner)
        | ASTRepr::Cos(inner)
        | ASTRepr::Sqrt(inner) => {
            collect_variables(inner, vars);
        }
        ASTRepr::Sum(collection) => {
            collect_variables_from_collection(collection, vars);
        }
        ASTRepr::Lambda(lambda) => {
            collect_variables(&lambda.body, vars);
        }
        ASTRepr::Constant(_) => {}
    }
}

fn collect_variables_from_collection(
    collection: &dslcompile::ast::ast_repr::Collection<f64>,
    vars: &mut std::collections::HashSet<usize>,
) {
    use dslcompile::ast::ast_repr::Collection;
    match collection {
        Collection::Empty => {}
        Collection::Singleton(expr) => collect_variables(expr, vars),
        Collection::Range { start, end } => {
            collect_variables(start, vars);
            collect_variables(end, vars);
        }
        Collection::Variable(index) => {
            vars.insert(*index);
        }
        Collection::Filter {
            collection,
            predicate,
        } => {
            collect_variables_from_collection(collection, vars);
            collect_variables(predicate, vars);
        }
        Collection::Map { lambda, collection } => {
            collect_variables(&lambda.body, vars);
            collect_variables_from_collection(collection, vars);
        }
        Collection::DataArray(_) => {
            // DataArray contains literal data, no variables to collect
        }
    }
}

fn compute_depth(ast: &ASTRepr<f64>) -> usize {
    match ast {
        ASTRepr::Constant(_) | ASTRepr::Variable(_) | ASTRepr::BoundVar(_) => 1,
        ASTRepr::Add(operands) => {
            let mut depth = 0;
            for (operand, _) in operands.iter_with_multiplicity() {
                depth = depth.max(compute_depth(operand));
            }
            depth + 1
        }
        ASTRepr::Sub(left, right) => {
            let left_depth = compute_depth(left);
            let right_depth = compute_depth(right);
            1 + left_depth.max(right_depth)
        }
        ASTRepr::Mul(operands) => {
            let mut depth = 0;
            for (operand, _) in operands.iter_with_multiplicity() {
                depth = depth.max(compute_depth(operand));
            }
            depth + 1
        }
        ASTRepr::Div(left, right) => {
            let left_depth = compute_depth(left);
            let right_depth = compute_depth(right);
            1 + left_depth.max(right_depth)
        }
        ASTRepr::Pow(left, right) => {
            let left_depth = compute_depth(left);
            let right_depth = compute_depth(right);
            1 + left_depth.max(right_depth)
        }
        ASTRepr::Let(_, expr, body) => {
            let expr_depth = compute_depth(expr);
            let body_depth = compute_depth(body);
            1 + expr_depth.max(body_depth)
        }
        ASTRepr::Neg(inner)
        | ASTRepr::Ln(inner)
        | ASTRepr::Exp(inner)
        | ASTRepr::Sin(inner)
        | ASTRepr::Cos(inner)
        | ASTRepr::Sqrt(inner) => 1 + compute_depth(inner),
        ASTRepr::Sum(_) => 2, // Summation adds depth
        ASTRepr::Lambda(lambda) => 1 + compute_depth(&lambda.body),
    }
}
