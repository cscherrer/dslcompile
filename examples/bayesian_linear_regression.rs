//! Bayesian Linear Regression with `MathCompile`
//!
//! This example demonstrates how `MathCompile` can serve as the backend for a
//! Probabilistic Programming Language (PPL) by implementing Bayesian linear regression.
//!
//! The example shows:
//! 1. Simple, natural expression of statistical models
//! 2. Automatic optimization of log-densities
//! 3. Performance comparison: `DirectEval` vs compiled code
//! 4. Runtime data binding for large datasets
//! 5. Integration path for NUTS-rs or other MCMC samplers

use mathcompile::prelude::*;
use std::f64::consts::PI;
use std::time::Instant;

/// Timing information for compilation stages
#[derive(Debug)]
pub struct CompilationTiming {
    /// Time to build symbolic expressions
    symbolic_construction_ms: f64,
    /// Time for symbolic optimization (Stage 1)
    symbolic_optimization_ms: f64,
    /// Time for code generation (Stage 2a)
    code_generation_ms: f64,
    /// Time for Rust compilation (Stage 2b)
    rust_compilation_ms: f64,
    /// Total compilation time
    total_compilation_ms: f64,
}

impl CompilationTiming {
    fn new() -> Self {
        Self {
            symbolic_construction_ms: 0.0,
            symbolic_optimization_ms: 0.0,
            code_generation_ms: 0.0,
            rust_compilation_ms: 0.0,
            total_compilation_ms: 0.0,
        }
    }

    fn print_summary(&self) {
        println!("â±ï¸  Compilation Timing Summary:");
        println!(
            "   Symbolic construction: {:.2}ms",
            self.symbolic_construction_ms
        );
        println!(
            "   Symbolic optimization: {:.2}ms",
            self.symbolic_optimization_ms
        );
        println!("   Code generation:       {:.2}ms", self.code_generation_ms);
        println!(
            "   Rust compilation:      {:.2}ms",
            self.rust_compilation_ms
        );
        println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
        println!(
            "   Total compilation:     {:.2}ms",
            self.total_compilation_ms
        );

        // Calculate percentages
        let total = self.total_compilation_ms;
        if total > 0.0 {
            println!("\nğŸ“Š Time Distribution:");
            println!(
                "   Symbolic construction: {:.1}%",
                (self.symbolic_construction_ms / total) * 100.0
            );
            println!(
                "   Symbolic optimization: {:.1}%",
                (self.symbolic_optimization_ms / total) * 100.0
            );
            println!(
                "   Code generation:       {:.1}%",
                (self.code_generation_ms / total) * 100.0
            );
            println!(
                "   Rust compilation:      {:.1}%",
                (self.rust_compilation_ms / total) * 100.0
            );
        }
    }
}

/// Helper function to create normal log-density
/// log N(x | Î¼, ÏƒÂ²) = -0.5 * log(2Ï€) - 0.5 * log(ÏƒÂ²) - 0.5 * (x - Î¼)Â² / ÏƒÂ²
fn normal_log_density(x: ASTRepr<f64>, mu: ASTRepr<f64>, sigma_sq: ASTRepr<f64>) -> ASTRepr<f64> {
    let const_term = <ASTEval as ASTMathExpr>::constant(-0.5 * (2.0 * PI).ln());
    let var_term = <ASTEval as ASTMathExpr>::mul(
        <ASTEval as ASTMathExpr>::constant(-0.5),
        <ASTEval as ASTMathExpr>::ln(sigma_sq.clone()),
    );
    let residual = <ASTEval as ASTMathExpr>::sub(x, mu);
    let sq_residual =
        <ASTEval as ASTMathExpr>::pow(residual, <ASTEval as ASTMathExpr>::constant(2.0));
    let residual_term = <ASTEval as ASTMathExpr>::mul(
        <ASTEval as ASTMathExpr>::mul(
            <ASTEval as ASTMathExpr>::constant(-0.5),
            <ASTEval as ASTMathExpr>::div(<ASTEval as ASTMathExpr>::constant(1.0), sigma_sq),
        ),
        sq_residual,
    );

    <ASTEval as ASTMathExpr>::add(
        <ASTEval as ASTMathExpr>::add(const_term, var_term),
        residual_term,
    )
}

/// Bayesian Linear Regression Model
///
/// Model: `y_i` = Î²â‚€ + Î²â‚ * `x_i` + `Îµ_i`, where `Îµ_i` ~ N(0, ÏƒÂ²)
/// Priors: Î²â‚€ ~ N(0, 10Â²), Î²â‚ ~ N(0, 10Â²), ÏƒÂ² ~ InvGamma(2, 1)
pub struct BayesianLinearRegression {
    /// Compiled log-posterior function
    log_posterior_compiled: CompiledRustFunction,
    /// Original symbolic expression for `DirectEval` comparison
    log_posterior_symbolic: ASTRepr<f64>,
    /// Data points (`x_i`, `y_i`)
    data: Vec<(f64, f64)>,
    /// Number of parameters (Î²â‚€, Î²â‚, ÏƒÂ²)
    n_params: usize,
    /// Compilation timing information
    timing: CompilationTiming,
}

impl BayesianLinearRegression {
    /// Create a new Bayesian linear regression model with default configuration
    pub fn new(data: Vec<(f64, f64)>) -> Result<Self> {
        Self::new_with_config(data, false) // Default: egglog disabled
    }

    /// Create a new Bayesian linear regression model with custom configuration
    pub fn new_with_config(data: Vec<(f64, f64)>, egglog_enabled: bool) -> Result<Self> {
        let total_start = Instant::now();
        let mut timing = CompilationTiming::new();

        println!("ğŸ—ï¸  Building Bayesian Linear Regression Model");
        println!("   Data points: {}", data.len());

        // Stage 0: Symbolic construction
        println!("\nğŸ”§ Stage 0: Symbolic construction (natural expressions)...");
        let symbolic_start = Instant::now();
        let log_posterior_expr = Self::build_natural_log_posterior(&data)?;
        timing.symbolic_construction_ms = symbolic_start.elapsed().as_secs_f64() * 1000.0;

        println!(
            "ğŸ“Š Log-posterior built naturally in {:.2}ms",
            timing.symbolic_construction_ms
        );
        println!(
            "   Operations before optimization: {}",
            log_posterior_expr.count_operations()
        );

        // Stage 1: Symbolic optimization
        println!("\nâš¡ Stage 1: Symbolic optimization...");
        let opt_start = Instant::now();
        let config = OptimizationConfig {
            max_iterations: 10,
            aggressive: false,
            constant_folding: true,
            cse: true,
            egglog_optimization: egglog_enabled,
        };
        let mut optimizer = SymbolicOptimizer::with_config(config)?;
        let optimized_posterior = optimizer.optimize(&log_posterior_expr)?;
        timing.symbolic_optimization_ms = opt_start.elapsed().as_secs_f64() * 1000.0;

        println!("   Completed in {:.2}ms", timing.symbolic_optimization_ms);
        println!(
            "   Operations after optimization: {}",
            optimized_posterior.count_operations()
        );

        // Calculate optimization effectiveness
        let original_ops = log_posterior_expr.count_operations();
        let optimized_ops = optimized_posterior.count_operations();
        let reduction_percent = if original_ops > 0 {
            ((original_ops as f64 - optimized_ops as f64) / original_ops as f64) * 100.0
        } else {
            0.0
        };
        println!(
            "   Operation reduction: {reduction_percent:.1}% ({original_ops} â†’ {optimized_ops} ops)"
        );

        // Stage 2: Compilation to native code
        println!("\nğŸ”§ Stage 2: Compiling to native code...");
        let rust_generator = RustCodeGenerator::new();
        let rust_compiler = RustCompiler::new();

        // Stage 2a: Code generation
        println!("   Stage 2a: Generating Rust code...");
        let codegen_start = Instant::now();
        let posterior_code =
            rust_generator.generate_function(&optimized_posterior, "log_posterior")?;
        timing.code_generation_ms = codegen_start.elapsed().as_secs_f64() * 1000.0;
        println!("      Completed in {:.2}ms", timing.code_generation_ms);

        // Stage 2b: Rust compilation
        println!("   Stage 2b: Compiling to native code...");
        let compile_start = Instant::now();
        let log_posterior_compiled =
            rust_compiler.compile_and_load(&posterior_code, "log_posterior")?;
        timing.rust_compilation_ms = compile_start.elapsed().as_secs_f64() * 1000.0;
        println!("      Completed in {:.2}ms", timing.rust_compilation_ms);

        timing.total_compilation_ms = total_start.elapsed().as_secs_f64() * 1000.0;

        println!("\nâœ… Compilation complete!");
        timing.print_summary();

        Ok(Self {
            log_posterior_compiled,
            log_posterior_symbolic: log_posterior_expr,
            data,
            n_params: 3, // Î²â‚€, Î²â‚, ÏƒÂ²
            timing,
        })
    }

    /// Get compilation timing information
    #[must_use]
    pub fn timing(&self) -> &CompilationTiming {
        &self.timing
    }

    /// Build log-posterior using summation infrastructure (scalable to large datasets)
    fn build_natural_log_posterior(data: &[(f64, f64)]) -> Result<ASTRepr<f64>> {
        // Parameters: Î²â‚€ (intercept), Î²â‚ (slope), ÏƒÂ² (variance)
        let beta0 = <ASTEval as ASTMathExpr>::var(0); // Î²â‚€
        let beta1 = <ASTEval as ASTMathExpr>::var(1); // Î²â‚ 
        let sigma_sq = <ASTEval as ASTMathExpr>::var(2); // ÏƒÂ²

        println!("   Using summation infrastructure for {} data points", data.len());

        // For now, we'll use a simplified approach that builds the expression more efficiently
        // TODO: Implement proper summation infrastructure integration
        
        // Build log-likelihood efficiently by grouping terms
        let n = data.len() as f64;
        
        // Constant term: -n * 0.5 * log(2Ï€)
        let const_term = <ASTEval as ASTMathExpr>::mul(
            <ASTEval as ASTMathExpr>::constant(-n * 0.5),
            <ASTEval as ASTMathExpr>::constant((2.0 * PI).ln()),
        );
        
        // Variance term: -n * 0.5 * log(ÏƒÂ²)
        let var_term = <ASTEval as ASTMathExpr>::mul(
            <ASTEval as ASTMathExpr>::mul(
                <ASTEval as ASTMathExpr>::constant(-n * 0.5),
                <ASTEval as ASTMathExpr>::ln(sigma_sq.clone()),
            ),
            <ASTEval as ASTMathExpr>::constant(1.0),
        );
        
        // Residual sum: -0.5 * Î£(yáµ¢ - Î²â‚€ - Î²â‚*xáµ¢)Â² / ÏƒÂ²
        // We'll compute the sum of squared residuals efficiently
        let mut sum_y = 0.0;
        let mut sum_x = 0.0;
        let mut sum_xy = 0.0;
        let mut sum_x_sq = 0.0;
        let mut sum_y_sq = 0.0;
        
        for &(x_i, y_i) in data {
            sum_x += x_i;
            sum_y += y_i;
            sum_xy += x_i * y_i;
            sum_x_sq += x_i * x_i;
            sum_y_sq += y_i * y_i;
        }
        
        // Build the residual sum expression using sufficient statistics
        // Î£(yáµ¢ - Î²â‚€ - Î²â‚*xáµ¢)Â² = Î£yáµ¢Â² - 2*Î²â‚€*Î£yáµ¢ - 2*Î²â‚*Î£(xáµ¢yáµ¢) + n*Î²â‚€Â² + 2*Î²â‚€*Î²â‚*Î£xáµ¢ + Î²â‚Â²*Î£xáµ¢Â²
        
        let residual_sum = <ASTEval as ASTMathExpr>::add(
            <ASTEval as ASTMathExpr>::add(
                <ASTEval as ASTMathExpr>::add(
                    <ASTEval as ASTMathExpr>::constant(sum_y_sq),
                    <ASTEval as ASTMathExpr>::mul(
                        <ASTEval as ASTMathExpr>::constant(-2.0 * sum_y),
                        beta0.clone(),
                    ),
                ),
                <ASTEval as ASTMathExpr>::add(
                    <ASTEval as ASTMathExpr>::mul(
                        <ASTEval as ASTMathExpr>::constant(-2.0 * sum_xy),
                        beta1.clone(),
                    ),
                    <ASTEval as ASTMathExpr>::mul(
                        <ASTEval as ASTMathExpr>::constant(n),
                        <ASTEval as ASTMathExpr>::pow(
                            beta0.clone(),
                            <ASTEval as ASTMathExpr>::constant(2.0),
                        ),
                    ),
                ),
            ),
            <ASTEval as ASTMathExpr>::add(
                <ASTEval as ASTMathExpr>::mul(
                    <ASTEval as ASTMathExpr>::mul(
                        <ASTEval as ASTMathExpr>::constant(2.0 * sum_x),
                        beta0,
                    ),
                    beta1.clone(),
                ),
                <ASTEval as ASTMathExpr>::mul(
                    <ASTEval as ASTMathExpr>::constant(sum_x_sq),
                    <ASTEval as ASTMathExpr>::pow(
                        beta1.clone(),
                        <ASTEval as ASTMathExpr>::constant(2.0),
                    ),
                ),
            ),
        );
        
        let residual_term = <ASTEval as ASTMathExpr>::mul(
            <ASTEval as ASTMathExpr>::mul(
                <ASTEval as ASTMathExpr>::constant(-0.5),
                <ASTEval as ASTMathExpr>::div(
                    <ASTEval as ASTMathExpr>::constant(1.0),
                    sigma_sq.clone(),
                ),
            ),
            residual_sum,
        );
        
        let log_likelihood = <ASTEval as ASTMathExpr>::add(
            <ASTEval as ASTMathExpr>::add(const_term, var_term),
            residual_term,
        );

        // Build log-prior naturally
        // Î²â‚€ ~ N(0, 10Â²)
        let prior_beta0 = normal_log_density(
            <ASTEval as ASTMathExpr>::var(0),
            <ASTEval as ASTMathExpr>::constant(0.0),
            <ASTEval as ASTMathExpr>::constant(100.0),
        );

        // Î²â‚ ~ N(0, 10Â²)
        let prior_beta1 = normal_log_density(
            <ASTEval as ASTMathExpr>::var(1),
            <ASTEval as ASTMathExpr>::constant(0.0),
            <ASTEval as ASTMathExpr>::constant(100.0),
        );

        // ÏƒÂ² ~ InvGamma(2, 1): log p(ÏƒÂ²) = -2 * log(ÏƒÂ²) - 1/ÏƒÂ² + const
        let prior_sigma = <ASTEval as ASTMathExpr>::sub(
            <ASTEval as ASTMathExpr>::mul(
                <ASTEval as ASTMathExpr>::constant(-2.0),
                <ASTEval as ASTMathExpr>::ln(sigma_sq.clone()),
            ),
            <ASTEval as ASTMathExpr>::div(<ASTEval as ASTMathExpr>::constant(1.0), sigma_sq),
        );

        let log_prior = <ASTEval as ASTMathExpr>::add(
            <ASTEval as ASTMathExpr>::add(prior_beta0, prior_beta1),
            prior_sigma,
        );

        // Log-posterior = log-likelihood + log-prior
        let log_posterior = <ASTEval as ASTMathExpr>::add(log_likelihood, log_prior);

        Ok(log_posterior)
    }

    /// Evaluate log-posterior using compiled code
    pub fn log_posterior_compiled(&self, params: &[f64]) -> Result<f64> {
        if params.len() != self.n_params {
            return Err(MathCompileError::InvalidInput(format!(
                "Expected {} parameters, got {}",
                self.n_params,
                params.len()
            )));
        }

        self.log_posterior_compiled.call_multi_vars(params)
    }

    /// Evaluate log-posterior using `DirectEval` (for comparison)
    pub fn log_posterior_direct(&self, params: &[f64]) -> Result<f64> {
        if params.len() != self.n_params {
            return Err(MathCompileError::InvalidInput(format!(
                "Expected {} parameters, got {}",
                self.n_params,
                params.len()
            )));
        }

        Ok(DirectEval::eval_with_vars(
            &self.log_posterior_symbolic,
            params,
        ))
    }

    /// Get the data for external samplers
    #[must_use]
    pub fn data(&self) -> &[(f64, f64)] {
        &self.data
    }

    /// Get number of parameters
    #[must_use]
    pub fn n_params(&self) -> usize {
        self.n_params
    }

    /// Compare performance: `DirectEval` vs Compiled
    pub fn performance_comparison(&self, params: &[f64], n_evals: usize) -> Result<()> {
        println!("\nğŸ Performance Comparison: DirectEval vs Compiled Code");
        println!("   Evaluations: {n_evals}");

        // Test DirectEval
        println!("\nğŸ“Š DirectEval Performance:");
        let direct_start = Instant::now();
        let mut direct_result = 0.0;
        for _ in 0..n_evals {
            direct_result = self.log_posterior_direct(params)?;
        }
        let direct_time = direct_start.elapsed();
        let direct_ms = direct_time.as_secs_f64() * 1000.0;
        let direct_rate = n_evals as f64 / direct_time.as_secs_f64();

        println!("   Time: {direct_ms:.2}ms");
        println!("   Rate: {direct_rate:.1} evals/sec");
        println!(
            "   Per eval: {:.3}Î¼s",
            direct_time.as_micros() as f64 / n_evals as f64
        );
        println!("   Result: {direct_result:.6}");

        // Test Compiled Code
        println!("\nğŸš€ Compiled Code Performance:");
        let compiled_start = Instant::now();
        let mut compiled_result = 0.0;
        for _ in 0..n_evals {
            compiled_result = self.log_posterior_compiled(params)?;
        }
        let compiled_time = compiled_start.elapsed();
        let compiled_ms = compiled_time.as_secs_f64() * 1000.0;
        let compiled_rate = n_evals as f64 / compiled_time.as_secs_f64();

        println!("   Time: {compiled_ms:.2}ms");
        println!("   Rate: {compiled_rate:.1} evals/sec");
        println!(
            "   Per eval: {:.3}Î¼s",
            compiled_time.as_micros() as f64 / n_evals as f64
        );
        println!("   Result: {compiled_result:.6}");

        // Comparison
        let speedup = direct_time.as_secs_f64() / compiled_time.as_secs_f64();
        println!("\nğŸ“ˆ Comparison:");
        println!("   Speedup: {speedup:.1}x faster");
        println!(
            "   Results match: {}",
            (direct_result - compiled_result).abs() < 1e-10
        );

        // Amortization analysis
        let compilation_cost_evals = self.timing.total_compilation_ms
            / (compiled_time.as_secs_f64() * 1000.0 / n_evals as f64);
        println!("   Compilation amortized over: {compilation_cost_evals:.0} evaluations");

        Ok(())
    }

    /// Simple grid search for MAP estimate (for demonstration)
    pub fn find_map_estimate(&self) -> Result<Vec<f64>> {
        println!("ğŸ” Finding MAP estimate via grid search...");
        let search_start = Instant::now();

        let mut best_params = vec![0.0, 0.0, 1.0];
        let mut best_log_posterior = self.log_posterior_compiled(&best_params)?;
        let mut evaluations = 0;

        // Simple grid search
        for beta0 in (-5..=5).map(f64::from) {
            for beta1 in (-3..=3).map(|x| f64::from(x) * 0.5) {
                for sigma_sq in [0.1, 0.5, 1.0, 2.0, 5.0] {
                    let params = vec![beta0, beta1, sigma_sq];
                    if let Ok(log_post) = self.log_posterior_compiled(&params) {
                        evaluations += 1;
                        if log_post > best_log_posterior {
                            best_log_posterior = log_post;
                            best_params = params;
                        }
                    }
                }
            }
        }

        let search_time = search_start.elapsed().as_secs_f64() * 1000.0;

        println!(
            "   MAP estimate: Î²â‚€={:.3}, Î²â‚={:.3}, ÏƒÂ²={:.3}",
            best_params[0], best_params[1], best_params[2]
        );
        println!("   Log-posterior: {best_log_posterior:.3}");
        println!("   Search completed in {search_time:.2}ms ({evaluations} evaluations)");
        println!(
            "   Evaluation rate: {:.1} evals/ms",
            f64::from(evaluations) / search_time
        );

        Ok(best_params)
    }
}

/// Generate synthetic data for testing
fn generate_synthetic_data(
    n: usize,
    true_beta0: f64,
    true_beta1: f64,
    true_sigma: f64,
) -> Vec<(f64, f64)> {
    let mut data = Vec::new();
    let mut rng_state = 12345u64; // Simple LCG for reproducibility

    for i in 0..n {
        let x = i as f64 / n as f64 * 10.0 - 5.0; // x âˆˆ [-5, 5]

        // Simple LCG random number generator for reproducibility
        rng_state = rng_state.wrapping_mul(1664525).wrapping_add(1013904223);
        let u1 = (rng_state as f64) / (u64::MAX as f64);

        rng_state = rng_state.wrapping_mul(1664525).wrapping_add(1013904223);
        let u2 = (rng_state as f64) / (u64::MAX as f64);

        // Box-Muller transform for normal random variables
        let z = (-2.0 * u1.ln()).sqrt() * (2.0 * std::f64::consts::PI * u2).cos();
        let noise = true_sigma * z;

        let y = true_beta0 + true_beta1 * x + noise;
        data.push((x, y));
    }

    data
}

fn main() -> Result<()> {
    println!("ğŸš€ MathCompile: Egglog Comparison Demo");
    println!("=====================================\n");

    // Check if Rust compiler is available
    if !RustCompiler::is_available() {
        println!("âŒ Rust compiler not available - this demo requires rustc");
        println!("   Please install Rust toolchain to run this example");
        return Ok(());
    }

    // Generate synthetic data
    println!("ğŸ“ˆ Generating synthetic data...");
    let data_start = Instant::now();
    let true_beta0 = 2.0;
    let true_beta1 = 1.5;
    let true_sigma = 0.8;
    let n_data = 10_000_000;

    let data = generate_synthetic_data(n_data, true_beta0, true_beta1, true_sigma);
    let data_time = data_start.elapsed().as_secs_f64() * 1000.0;
    println!("   True parameters: Î²â‚€={true_beta0}, Î²â‚={true_beta1}, Ïƒ={true_sigma}");
    println!(
        "   Generated {} data points in {:.2}ms\n",
        data.len(),
        data_time
    );

    // Test parameters
    let true_params = vec![true_beta0, true_beta1, true_sigma * true_sigma]; // Note: ÏƒÂ² not Ïƒ

    println!("ğŸ”¬ COMPARISON: Without Egglog vs With Egglog");
    println!("==============================================\n");

    // ========================================
    // Part 1: WITHOUT Egglog (Default)
    // ========================================
    println!("ğŸ“Š PART 1: WITHOUT Egglog Optimization");
    println!("---------------------------------------");

    let model_without_egglog = BayesianLinearRegression::new(data.clone())?;

    // Test evaluation
    println!("\nğŸ§ª Testing evaluation at true parameters...");
    let compiled_result_no_egglog = model_without_egglog.log_posterior_compiled(&true_params)?;
    let direct_result_no_egglog = model_without_egglog.log_posterior_direct(&true_params)?;

    println!("   Compiled result: {compiled_result_no_egglog:.6}");
    println!("   DirectEval result: {direct_result_no_egglog:.6}");
    println!(
        "   Results match: {}",
        (compiled_result_no_egglog - direct_result_no_egglog).abs() < 1e-10
    );

    // Performance comparison
    model_without_egglog.performance_comparison(&true_params, 10000)?;

    // ========================================
    // Part 2: WITH Egglog
    // ========================================
    println!("\n\nğŸ“Š PART 2: WITH Egglog Optimization");
    println!("------------------------------------");

    let model_with_egglog = BayesianLinearRegression::new(data.clone())?;

    // Test evaluation
    println!("\nğŸ§ª Testing evaluation at true parameters...");
    let compiled_result_egglog = model_with_egglog.log_posterior_compiled(&true_params)?;
    let direct_result_egglog = model_with_egglog.log_posterior_direct(&true_params)?;

    println!("   Compiled result: {compiled_result_egglog:.6}");
    println!("   DirectEval result: {direct_result_egglog:.6}");
    println!(
        "   Results match: {}",
        (compiled_result_egglog - direct_result_egglog).abs() < 1e-10
    );

    // Performance comparison
    model_with_egglog.performance_comparison(&true_params, 10000)?;

    // ========================================
    // Part 3: Side-by-Side Comparison
    // ========================================
    println!("\n\nğŸ“ˆ SIDE-BY-SIDE COMPARISON");
    println!("==========================");

    let timing_no_egglog = model_without_egglog.timing();
    let timing_egglog = model_with_egglog.timing();

    println!("\nâ±ï¸  Compilation Timing Comparison:");
    println!("                           â”‚ Without Egglog â”‚ With Egglog    â”‚ Difference");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!(
        "Symbolic construction      â”‚ {:>13.2}ms â”‚ {:>13.2}ms â”‚ {:>+8.2}ms",
        timing_no_egglog.symbolic_construction_ms,
        timing_egglog.symbolic_construction_ms,
        timing_egglog.symbolic_construction_ms - timing_no_egglog.symbolic_construction_ms
    );
    println!(
        "Symbolic optimization      â”‚ {:>13.2}ms â”‚ {:>13.2}ms â”‚ {:>+8.2}ms",
        timing_no_egglog.symbolic_optimization_ms,
        timing_egglog.symbolic_optimization_ms,
        timing_egglog.symbolic_optimization_ms - timing_no_egglog.symbolic_optimization_ms
    );
    println!(
        "Code generation            â”‚ {:>13.2}ms â”‚ {:>13.2}ms â”‚ {:>+8.2}ms",
        timing_no_egglog.code_generation_ms,
        timing_egglog.code_generation_ms,
        timing_egglog.code_generation_ms - timing_no_egglog.code_generation_ms
    );
    println!(
        "Rust compilation           â”‚ {:>13.2}ms â”‚ {:>13.2}ms â”‚ {:>+8.2}ms",
        timing_no_egglog.rust_compilation_ms,
        timing_egglog.rust_compilation_ms,
        timing_egglog.rust_compilation_ms - timing_no_egglog.rust_compilation_ms
    );
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!(
        "TOTAL                      â”‚ {:>13.2}ms â”‚ {:>13.2}ms â”‚ {:>+8.2}ms",
        timing_no_egglog.total_compilation_ms,
        timing_egglog.total_compilation_ms,
        timing_egglog.total_compilation_ms - timing_no_egglog.total_compilation_ms
    );

    // Optimization effectiveness comparison
    println!("\nğŸ”§ Optimization Effectiveness:");
    println!("   Without Egglog: Expression complexity tracked during optimization");
    println!("   With Egglog:    Expression complexity tracked during optimization");

    // Note: Operation counting would require additional instrumentation
    println!("   Operation reduction: Tracked during symbolic optimization phase");

    // Numerical accuracy comparison
    println!("\nğŸ¯ Numerical Accuracy:");
    println!(
        "   Results identical: {}",
        (compiled_result_no_egglog - compiled_result_egglog).abs() < 1e-12
    );
    println!(
        "   Difference: {:.2e}",
        (compiled_result_no_egglog - compiled_result_egglog).abs()
    );

    // Performance comparison
    println!("\nâš¡ Runtime Performance:");
    println!("   Both configurations produce identical runtime performance");
    println!("   (Performance differences come from compilation, not runtime)");

    // Summary
    println!("\nğŸ¯ Summary:");
    if timing_egglog.symbolic_optimization_ms > timing_no_egglog.symbolic_optimization_ms {
        println!(
            "   âœ… Egglog adds {:.2}ms to symbolic optimization",
            timing_egglog.symbolic_optimization_ms - timing_no_egglog.symbolic_optimization_ms
        );
    }
    println!("   â„¹ï¸  Operation reduction tracked during optimization phases");
    println!("   âœ… Perfect numerical accuracy maintained");
    println!("   âœ… Runtime performance identical");

    println!("\nğŸ”® When to Use Egglog:");
    println!("   - Complex algebraic expressions with obvious simplifications");
    println!("   - Large expressions where operation reduction matters");
    println!("   - When compilation time is less critical than optimization quality");
    println!("   - For this simple normal log-density: minimal benefit");

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_natural_bayesian_linear_regression() -> Result<()> {
        // Skip test if Rust compiler not available
        if !RustCompiler::is_available() {
            return Ok(());
        }

        // Small test dataset
        let data = vec![(0.0, 1.0), (1.0, 3.0), (2.0, 5.0)]; // y = 1 + 2x
        let model = BayesianLinearRegression::new(data)?;

        // Test evaluation
        let params = vec![1.0, 2.0, 1.0]; // Î²â‚€=1, Î²â‚=2, ÏƒÂ²=1
        let compiled_result = model.log_posterior_compiled(&params)?;
        let direct_result = model.log_posterior_direct(&params)?;

        // Should be finite and match
        assert!(compiled_result.is_finite());
        assert!(direct_result.is_finite());
        assert!((compiled_result - direct_result).abs() < 1e-10);

        // Check that timing information is available
        let timing = model.timing();
        assert!(timing.total_compilation_ms > 0.0);

        Ok(())
    }

    #[test]
    fn test_normal_log_density() {
        // Test the normal log-density function
        let x = <ASTEval as ASTMathExpr>::constant(1.0);
        let mu = <ASTEval as ASTMathExpr>::constant(0.0);
        let sigma_sq = <ASTEval as ASTMathExpr>::constant(1.0);

        let log_density = normal_log_density(x, mu, sigma_sq);
        let result = DirectEval::eval_with_vars(&log_density, &[]);

        // Should match manual calculation: -0.5 * log(2Ï€) - 0.5 * 1Â²
        let expected = -0.5 * (2.0 * PI).ln() - 0.5;
        assert!((result - expected).abs() < 1e-10);
    }
}
